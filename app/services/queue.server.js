import Bull from 'bull';
import Redis from 'ioredis';
import { translateResourceWithLogging } from './translation.server.js';
import shopify from '../shopify.server.js';
import { updateResourceTranslation } from './shopify-graphql.server.js';
import { saveTranslation, updateResourceStatus, prisma } from './database.server.js';
// import { authenticate } from '../shopify.server.js'; // åªåœ¨éœ€è¦æ—¶å¯¼å…¥
import { config } from '../utils/config.server.js';
import { MemoryQueue } from './memory-queue.server.js';
import { collectError, ERROR_TYPES } from './error-collector.server.js';
import { createShopRedisConfig, parseRedisUrl } from '../utils/redis-parser.server.js';

/**
 * Redisä»»åŠ¡é˜Ÿåˆ—æœåŠ¡
 * æ”¯æŒRailwayã€Upstashç­‰äº‘RedisæœåŠ¡
 * å®ç°å¤šåº—é“ºæ•°æ®éš”ç¦»å’Œè‡ªåŠ¨é™çº§
 */

// è·å–å½“å‰åº—é“ºIDï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
const SHOP_ID = process.env.SHOP_ID || 'default';

// Redisè¿æ¥é…ç½®
let redisConfig = null;
if (config.redis.enabled && process.env.REDIS_URL) {
  // ä½¿ç”¨è§£æå™¨åˆ›å»ºåº—é“ºéš”ç¦»çš„Redisé…ç½®
  redisConfig = createShopRedisConfig(process.env.REDIS_URL, SHOP_ID, {
    // é’ˆå¯¹äº‘RedisæœåŠ¡çš„ä¼˜åŒ–
    maxRetriesPerRequest: 2,
    enableReadyCheck: false,
    connectTimeout: 10000,
    commandTimeout: 5000,
    lazyConnect: true,

    // é˜Ÿåˆ—ä¸“ç”¨ä¼˜åŒ–
    enableOfflineQueue: false,
    retryDelayOnFailover: 500,

    // é”™è¯¯å¤„ç†
    reconnectOnError: (err) => {
      console.warn(`Redisè¿æ¥é”™è¯¯ [Shop: ${SHOP_ID}]:`, err.message);
      const retryableErrors = ['READONLY', 'ECONNRESET', 'EPIPE', 'ENOTFOUND', 'TIMEOUT'];
      return retryableErrors.some(e => err.message.includes(e));
    }
  });
} else if (config.redis.enabled && config.redis.host) {
  // ä¼ ç»Ÿé…ç½®æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
  redisConfig = {
    host: config.redis.host,
    port: config.redis.port,
    password: config.redis.password || undefined,
    db: getShopRedisDb(SHOP_ID),
    maxRetriesPerRequest: 3,
    lazyConnect: true,
  };
}

/**
 * æ ¹æ®åº—é“ºIDè·å–Redisæ•°æ®åº“ç´¢å¼•
 * @param {string} shopId - åº—é“ºID
 * @returns {number} æ•°æ®åº“ç´¢å¼• (0-15)
 */
function getShopRedisDb(shopId) {
  if (!shopId || shopId === 'default') return 0;

  // ç®€å•æ˜ å°„ï¼šshop1->1, shop2->2, ç­‰ç­‰
  const match = shopId.match(/shop(\d+)/);
  if (match) {
    const num = parseInt(match[1]);
    return Math.min(num, 15); // Redisæœ€å¤š16ä¸ªæ•°æ®åº“ (0-15)
  }

  // å¦‚æœä¸æ˜¯æ ‡å‡†æ ¼å¼ï¼Œä½¿ç”¨å“ˆå¸Œ
  let hash = 0;
  for (let i = 0; i < shopId.length; i++) {
    hash = ((hash << 5) - hash) + shopId.charCodeAt(i);
    hash = hash & hash;
  }
  return Math.abs(hash) % 16;
}

// åˆ›å»ºRedisè¿æ¥
let redis;
let redisConnectionAttempts = 0;
const MAX_REDIS_ATTEMPTS = 3;

const QUEUE_NAME = SHOP_ID !== 'default' ? `translation_${SHOP_ID}` : 'translation';
const FALLBACK_CONCURRENCY = Math.max(1, Math.min(config.queue?.concurrency || 1, 4));
const REQUIRED_JOB_FIELDS = ['resourceId', 'shopId', 'shopDomain', 'language'];

function assertJobPayload(payload) {
  const missing = REQUIRED_JOB_FIELDS.filter((field) => !payload?.[field]);
  if (missing.length > 0) {
    const error = new Error(`Missing required job fields: ${missing.join(', ')}`);
    error.code = 'QUEUE_JOB_VALIDATION';
    throw error;
  }
}

function assertBatchJobPayload(payload) {
  const baseMissing = ['shopId', 'shopDomain', 'language'].filter((field) => !payload?.[field]);
  const listMissing = !Array.isArray(payload?.resourceIds) || payload.resourceIds.length === 0;

  if (baseMissing.length > 0 || listMissing) {
    const parts = [];
    if (baseMissing.length > 0) {
      parts.push(`missing fields: ${baseMissing.join(', ')}`);
    }
    if (listMissing) {
      parts.push('resourceIds must be a non-empty array');
    }
    const error = new Error(`Invalid batch job payload (${parts.join('; ')})`);
    error.code = 'QUEUE_BATCH_JOB_VALIDATION';
    throw error;
  }
}

function createAdminClient(shopDomain, accessToken) {
  if (!shopDomain) {
    throw new Error('ç¼ºå°‘ shopDomainï¼Œæ— æ³•åˆ›å»º Shopify Admin å®¢æˆ·ç«¯');
  }
  if (!accessToken) {
    throw new Error(`åº—é“º ${shopDomain} ç¼ºå°‘ accessTokenï¼Œæ— æ³•åˆ›å»º Shopify Admin å®¢æˆ·ç«¯`);
  }

  const configuredScopes = Array.isArray(shopify.api?.config?.scopes)
    ? shopify.api.config.scopes.join(',')
    : (shopify.api?.config?.scopes || process.env.SCOPES || '');

  const session = {
    id: `offline_${shopDomain}`,
    shop: shopDomain,
    state: 'offline',
    isOnline: false,
    scope: configuredScopes,
    accessToken
  };

  const graphqlClient = new shopify.api.clients.Graphql({
    session,
    apiVersion: shopify.api?.config?.apiVersion
  });

  return {
    graphql: async (query, options = {}) => {
      const result = await graphqlClient.request(query, {
        variables: options?.variables,
        retries: options?.tries ? options.tries - 1 : 0,
        headers: options?.headers,
        signal: options?.signal
      });

      return new Response(JSON.stringify(result));
    }
  };
}

const processorDefinitions = [];
const attachedQueues = new WeakSet();
let processorsInitialized = false;
let translationQueue;
let useMemoryQueue = false;
let isSwitchingQueue = false;
let healthCheckTimer = null;
let redisRecoveryNotified = false;

try {
  if (config.redis.enabled && redisConfig) {
    console.log(`[Queue] åˆå§‹åŒ–Redisè¿æ¥ [Shop: ${SHOP_ID}, DB: ${redisConfig.db || 0}]`);
    redis = new Redis(redisConfig);

    // å¤„ç†è¿æ¥é”™è¯¯
    redis.on('error', (error) => {
      // å¿½ç•¥å¸¸è§çš„éè‡´å‘½é”™è¯¯
      const ignorableErrors = ['ECONNRESET', 'EPIPE', 'ETIMEDOUT'];
      if (ignorableErrors.some(e => error.message.includes(e))) {
        console.debug('Redisè¿æ¥ä¸´æ—¶ä¸­æ–­:', error.message);
        return;
      }

      if (!redis._isConnected && redisConnectionAttempts >= MAX_REDIS_ATTEMPTS) {
        console.warn('Redisè¿æ¥å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å†…å­˜æ¨¡å¼');
        redis = null;
      }
    });

    // æˆåŠŸè¿æ¥åé‡ç½®è®¡æ•°å™¨
    redis.on('connect', () => {
      redisConnectionAttempts = 0;
      console.log('Redisè¿æ¥æˆåŠŸ');
    });
  } else {
    console.log('Redisæœªé…ç½®ï¼Œå°†ä½¿ç”¨å†…å­˜æ¨¡å¼');
    redis = null;
  }
} catch (error) {
  console.warn('Redisè¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨å†…å­˜æ¨¡å¼:', error.message);
  redis = null;
}

useMemoryQueue = !redis;

function ensureProcessorDefinitions() {
  if (processorsInitialized) {
    return processorDefinitions;
  }

  processorDefinitions.push({
    name: 'translateResource',
    concurrency: () => config.queue?.concurrency || 1,
    handler: handleTranslateResource
  });

  processorDefinitions.push({
    name: 'batchTranslate',
    concurrency: () => 1,
    handler: handleBatchTranslate
  });

  processorsInitialized = true;
  return processorDefinitions;
}

function registerProcessors(queue) {
  if (!queue || typeof queue.process !== 'function') {
    return;
  }

  const definitions = ensureProcessorDefinitions();

  for (const definition of definitions) {
    const concurrency = Math.max(1, definition.concurrency());
    const handler = definition.handler;
    const boundHandler = handler.length > 1
      ? (job) => handler(job, queue)
      : handler;

    queue.process(definition.name, concurrency, boundHandler);
  }
}

function attachLifecycleEvents(queue) {
  if (!queue || typeof queue.on !== 'function' || attachedQueues.has(queue)) {
    return;
  }

  attachedQueues.add(queue);

  queue.on('error', async (error) => {
    console.error('é˜Ÿåˆ—é”™è¯¯:', error);

    try {
      await collectError({
        errorType: ERROR_TYPES.SYSTEM,
        errorCategory: 'QUEUE_SYSTEM',
        errorCode: 'QUEUE_ERROR',
        message: `Queue system error: ${error?.message || error}`,
        stack: error?.stack,
        operation: 'queue.system',
        severity: 4,
        retryable: false,
        context: {
          queueMode: useMemoryQueue ? 'memory' : 'redis'
        }
      });
    } catch (collectErr) {
      console.warn('è®°å½•é˜Ÿåˆ—ç³»ç»Ÿé”™è¯¯å¤±è´¥:', collectErr?.message || collectErr);
    }

    if (!useMemoryQueue) {
      await requestMemoryFallback(`Redisé˜Ÿåˆ—å‡ºé”™ï¼Œåˆ‡æ¢åˆ°å†…å­˜æ¨¡å¼: ${error?.message || error}`);
    }
  });

  queue.on('failed', async (job, err) => {
    console.error(`ä»»åŠ¡å¤±è´¥ ${job?.id}:`, err);

    try {
      await collectError({
        errorType: ERROR_TYPES.TRANSLATION,
        errorCategory: 'QUEUE_FAILED',
        errorCode: err?.code || 'JOB_FAILED',
        message: `Job ${job?.id} failed after ${job?.attemptsMade ?? job?.attempts ?? 0} attempts: ${err?.message || err}`,
        stack: err?.stack,
        operation: 'queue.job',
        resourceId: job?.data?.resourceId,
        severity: 3,
        retryable: (job?.attemptsMade ?? job?.attempts ?? 0) < (job?.opts?.attempts ?? job?.maxAttempts ?? 3),
        context: {
          jobId: job?.id,
          jobName: job?.name,
          attempts: job?.attemptsMade ?? job?.attempts ?? 0,
          maxAttempts: job?.opts?.attempts ?? job?.maxAttempts ?? 3,
          data: job?.data,
          failedReason: job?.failedReason
        }
      });
    } catch (collectErr) {
      console.warn('è®°å½•ä»»åŠ¡å¤±è´¥é”™è¯¯å¤±è´¥:', collectErr?.message || collectErr);
    }
  });

  queue.on('completed', (job, result) => {
    console.log(`ä»»åŠ¡å®Œæˆ ${job?.id}:`, result);
  });
}

function createBullQueue() {
  if (!redisConfig) {
    throw new Error('Redisé…ç½®ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºBullé˜Ÿåˆ—');
  }

  console.log(`[Queue] åˆ›å»ºBullé˜Ÿåˆ— [Shop: ${SHOP_ID}, Queue: ${QUEUE_NAME}]`);

  return new Bull(QUEUE_NAME, {
    redis: redisConfig,
    defaultJobOptions: {
      removeOnComplete: 10, // ä¿ç•™æœ€è¿‘10ä¸ªå®Œæˆä»»åŠ¡
      removeOnFail: 5,      // ä¿ç•™æœ€è¿‘5ä¸ªå¤±è´¥ä»»åŠ¡
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 2000
      },
      delay: 100, // æ·»åŠ 100mså»¶è¿Ÿé¿å…è¿‡å¿«å¤„ç†
    },
    settings: {
      stalledInterval: 30000,    // 30ç§’æ£€æŸ¥ä¸€æ¬¡å¡ä½çš„ä»»åŠ¡
      retryProcessDelay: 5000,   // 5ç§’åé‡è¯•å¤„ç†
    }
  });
}

function createMemoryQueueInstance() {
  return new MemoryQueue(QUEUE_NAME, { defaultConcurrency: FALLBACK_CONCURRENCY });
}

function stopHealthCheck() {
  if (healthCheckTimer) {
    clearInterval(healthCheckTimer);
    healthCheckTimer = null;
  }
  redisRecoveryNotified = false;
}

function startHealthCheck() {
  if (!redis || healthCheckTimer) {
    return;
  }

  healthCheckTimer = setInterval(async () => {
    if (!useMemoryQueue) {
      redisRecoveryNotified = false;
      return;
    }

    try {
      await redis.ping();
      if (!redisRecoveryNotified) {
        console.log('ğŸ”„ æ£€æµ‹åˆ°Redisæ¢å¤ï¼Œå¯æ‰‹åŠ¨åˆ‡å›Redisé˜Ÿåˆ—');
        redisRecoveryNotified = true;
      }
    } catch (error) {
      redisRecoveryNotified = false;
      console.debug('Redisä»ä¸å¯ç”¨:', error?.message || error);
    }
  }, 30000);

  if (typeof healthCheckTimer.unref === 'function') {
    healthCheckTimer.unref();
  }
}

async function requestMemoryFallback(reason) {
  if (useMemoryQueue || isSwitchingQueue) {
    return;
  }

  isSwitchingQueue = true;
  redisRecoveryNotified = false;
  console.warn(reason);

  const previousQueue = translationQueue;
  const memoryQueue = createMemoryQueueInstance();

  translationQueue = memoryQueue;
  useMemoryQueue = true;

  registerProcessors(memoryQueue);
  attachLifecycleEvents(memoryQueue);

  console.log('âš ï¸ é˜Ÿåˆ—å·²åˆ‡æ¢åˆ°å†…å­˜æ¨¡å¼');

  if (previousQueue?.close) {
    try {
      await previousQueue.close();
    } catch (error) {
      console.warn('å…³é—­Redisé˜Ÿåˆ—å¤±è´¥:', error?.message || error);
    }
  }

  isSwitchingQueue = false;
  startHealthCheck();
}

function initializeQueue() {
  if (!useMemoryQueue) {
    try {
      translationQueue = createBullQueue();
    } catch (error) {
      console.warn('Bullé˜Ÿåˆ—åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨å†…å­˜æ¨¡å¼:', error?.message || error);
      useMemoryQueue = true;
    }
  }

  if (useMemoryQueue || !translationQueue) {
    translationQueue = createMemoryQueueInstance();
    useMemoryQueue = true;
  }

  registerProcessors(translationQueue);
  attachLifecycleEvents(translationQueue);

  if (useMemoryQueue) {
    startHealthCheck();
  } else {
    stopHealthCheck();
  }

  console.log(`ğŸš€ ç¿»è¯‘é˜Ÿåˆ—å·²å¯åŠ¨: ${useMemoryQueue ? 'å†…å­˜æ¨¡å¼' : 'Redisæ¨¡å¼'}`);
}

async function handleTranslateResource(job) {
  assertJobPayload(job?.data);
  const { resourceId, shopId, shopDomain, language } = job.data;
  let resource;

  try {
    job.progress(10);

    resource = await prisma.resource.findUnique({
      where: { id: resourceId }
    });

    if (!resource) {
      throw new Error(`èµ„æº ${resourceId} ä¸å­˜åœ¨`);
    }

    await updateResourceStatus(resourceId, 'processing');
    job.progress(20);

    let shop = await prisma.shop.findUnique({
      where: { id: shopId }
    });

    if (!shop && shopDomain) {
      shop = await prisma.shop.findUnique({
        where: { id: shopDomain }
      }) || await prisma.shop.findUnique({
        where: { domain: shopDomain }
      });
    }

    if (!shop) {
      throw new Error(`åº—é“º ${shopId || shopDomain} ä¸å­˜åœ¨`);
    }

    if (!shop.accessToken) {
      throw new Error(`åº—é“º ${shop.domain} ç¼ºå°‘è®¿é—®ä»¤ç‰Œï¼Œæ— æ³•ç¿»è¯‘`);
    }

    const admin = createAdminClient(shop.domain, shop.accessToken);

    const translationResult = await translateResourceWithLogging(resource, language, admin);
    job.progress(50);

    if (translationResult.skipped) {
      console.log(`â„¹ï¸ è·³è¿‡ç¿»è¯‘ï¼Œå†…å®¹æœªå˜åŒ–: ${resource.title}`);
      await updateResourceStatus(resourceId, 'pending');
      job.progress(100);
      return {
        resourceId,
        resourceType: resource.resourceType,
        title: resource.title,
        success: true,
        skipped: true,
        skipReason: translationResult.skipReason
      };
    }

    await saveTranslation(resourceId, shopId, language, translationResult.translations);
    job.progress(70);

    console.log(`âœ… ç¿»è¯‘å®Œæˆï¼ŒçŠ¶æ€è®¾ä¸ºpendingç­‰å¾…å‘å¸ƒ: ${resource.title} -> ${language}`);
    job.progress(90);

    await updateResourceStatus(resourceId, 'completed');
    job.progress(100);

    return {
      resourceId,
      resourceType: resource.resourceType,
      title: resource.title,
      success: true,
      translations: translationResult.translations
    };
  } catch (error) {
    console.error(`ç¿»è¯‘ä»»åŠ¡å¤±è´¥ ${resourceId}:`, error);

    try {
      await collectError({
        errorType: ERROR_TYPES.TRANSLATION,
        errorCategory: 'QUEUE_ERROR',
        errorCode: error?.code || 'QUEUE_TRANSLATION_FAILED',
        message: `Queue translation failed for resource ${resourceId}: ${error?.message || error}`,
        stack: error?.stack,
        operation: 'queue.translateResource',
        resourceId,
        resourceType: resource?.resourceType || 'UNKNOWN',
        targetLanguage: language,
        severity: 3,
        retryable: true,
        context: {
          shopId,
          shopDomain,
          jobId: job?.id,
          attempt: job?.attemptsMade ?? job?.attempts ?? 0,
          maxAttempts: job?.opts?.attempts ?? job?.maxAttempts ?? 3
        }
      });
    } catch (collectErr) {
      console.warn('è®°å½•ç¿»è¯‘ä»»åŠ¡é”™è¯¯å¤±è´¥:', collectErr?.message || collectErr);
    }

    try {
      await updateResourceStatus(resourceId, 'pending');
    } catch (statusError) {
      console.warn('æ›´æ–°èµ„æºçŠ¶æ€å¤±è´¥:', statusError?.message || statusError);
    }

    throw error;
  }
}

async function handleBatchTranslate(job, queue) {
  assertBatchJobPayload(job?.data);
  const { resourceIds = [], shopId, shopDomain, language } = job.data;
  const results = [];
  const total = resourceIds.length;

  if (!queue || typeof queue.add !== 'function') {
    throw new Error('å½“å‰é˜Ÿåˆ—ä¸æ”¯æŒæ‰¹é‡ç¿»è¯‘');
  }

  for (let index = 0; index < resourceIds.length; index++) {
    const resourceId = resourceIds[index];

    try {
      const singleJobPayload = {
        resourceId,
        shopId,
        shopDomain,
        language
      };

      assertJobPayload(singleJobPayload);

      const translateJob = await queue.add('translateResource', singleJobPayload, {
        attempts: 3,
        backoff: 'exponential',
        delay: index * 1000
      });

      const result = await translateJob.finished();
      results.push(result);
    } catch (error) {
      results.push({
        resourceId,
        success: false,
        error: error?.message || String(error)
      });
    }

    if (total > 0) {
      job.progress(Math.round(((index + 1) / total) * 100));
    }
  }

  return {
    total,
    success: results.filter((item) => item?.success).length,
    failure: results.filter((item) => !item?.success).length,
    results
  };
}

initializeQueue();

export { translationQueue };

/**
 * æ·»åŠ ç¿»è¯‘ä»»åŠ¡åˆ°é˜Ÿåˆ—
 * @param {string} resourceId - èµ„æºID
 * @param {string} shopId - åº—é“ºID
 * @param {string} language - ç›®æ ‡è¯­è¨€
 * @param {string} shopDomain - åº—é“ºåŸŸå
 * @param {Object} options - ä»»åŠ¡é€‰é¡¹
 * @returns {Promise<Object>} ä»»åŠ¡ä¿¡æ¯
 */
export async function addTranslationJob(resourceId, shopId, language, shopDomain, options = {}) {
  if (!translationQueue) {
    throw new Error('ä»»åŠ¡é˜Ÿåˆ—æœªé…ç½®ï¼Œæ— æ³•åˆ›å»ºå¼‚æ­¥ä»»åŠ¡');
  }

  const jobData = {
    resourceId,
    shopId,
    shopDomain,
    language
  };

  assertJobPayload(jobData);

  const job = await translationQueue.add('translateResource', jobData, {
    attempts: 3,
    backoff: 'exponential',
    removeOnComplete: 10,
    removeOnFail: 5,
    ...options
  });

  return {
    jobId: job.id,
    resourceId,
    shopDomain,
    status: 'queued'
  };
}

/**
 * æ·»åŠ æ‰¹é‡ç¿»è¯‘ä»»åŠ¡åˆ°é˜Ÿåˆ—
 * @param {Array} resourceIds - èµ„æºIDåˆ—è¡¨
 * @param {string} shopId - åº—é“ºID
 * @param {string} language - ç›®æ ‡è¯­è¨€
 * @param {string} shopDomain - åº—é“ºåŸŸå
 * @returns {Promise<Object>} ä»»åŠ¡ä¿¡æ¯
 */
export async function addBatchTranslationJob(resourceIds, shopId, language, shopDomain) {
  if (!translationQueue) {
    throw new Error('ä»»åŠ¡é˜Ÿåˆ—æœªé…ç½®ï¼Œæ— æ³•åˆ›å»ºæ‰¹é‡ä»»åŠ¡');
  }

  const jobData = {
    resourceIds,
    shopId,
    shopDomain,
    language
  };

  assertBatchJobPayload(jobData);

  const job = await translationQueue.add('batchTranslate', jobData, {
    attempts: 1,
    removeOnComplete: 5,
    removeOnFail: 5
  });

  return {
    jobId: job.id,
    resourceCount: resourceIds.length,
    shopDomain,
    status: 'queued'
  };
}

/**
 * è·å–ä»»åŠ¡çŠ¶æ€
 * @param {string} jobId - ä»»åŠ¡ID
 * @returns {Promise<Object>} ä»»åŠ¡çŠ¶æ€
 */
export async function getJobStatus(jobId) {
  if (!translationQueue) {
    return { error: 'ä»»åŠ¡é˜Ÿåˆ—æœªé…ç½®' };
  }

  const job = await translationQueue.getJob(jobId);

  if (!job) {
    return { error: 'ä»»åŠ¡ä¸å­˜åœ¨' };
  }

  const progress = typeof job.progress === 'function' ? job.progress() : job.progress;
  const state = typeof job.getState === 'function' ? await job.getState() : job.status;

  return {
    id: job.id,
    progress,
    state,
    createdAt: job.timestamp ? new Date(job.timestamp) : job.createdAt ? new Date(job.createdAt) : null,
    processedAt: job.processedOn ? new Date(job.processedOn) : null,
    finishedAt: job.finishedOn ? new Date(job.finishedOn) : job.completedAt ? new Date(job.completedAt) : null,
    failedReason: job.failedReason || job.error,
    data: job.data
  };
}

/**
 * è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
 * @returns {Promise<Object>} é˜Ÿåˆ—ç»Ÿè®¡
 */
export async function getQueueStats() {
  if (!translationQueue) {
    return { error: 'ä»»åŠ¡é˜Ÿåˆ—æœªé…ç½®' };
  }

  const waiting = await translationQueue.getWaiting();
  const active = await translationQueue.getActive();
  const completed = await translationQueue.getCompleted();
  const failed = await translationQueue.getFailed();

  return {
    waiting: waiting.length,
    active: active.length,
    completed: completed.length,
    failed: failed.length,
    total: waiting.length + active.length + completed.length + failed.length
  };
}

/**
 * æ¸…ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
 * @param {string} type - æ¸…ç†ç±»å‹: 'completed', 'failed', 'all'
 * @returns {Promise<Object>} æ¸…ç†ç»“æœ
 */
export async function cleanQueue(type = 'completed') {
  if (!translationQueue) {
    return { error: 'ä»»åŠ¡é˜Ÿåˆ—æœªé…ç½®' };
  }

  let cleaned = 0;

  switch (type) {
    case 'completed':
      cleaned = await translationQueue.clean(5000, 'completed');
      break;
    case 'failed':
      cleaned = await translationQueue.clean(5000, 'failed');
      break;
    case 'all':
      const completedCleaned = await translationQueue.clean(0, 'completed');
      const failedCleaned = await translationQueue.clean(0, 'failed');
      cleaned = completedCleaned + failedCleaned;
      break;
    default:
      break;
  }

  return {
    cleaned,
    type
  };
}

// å¯¼å‡ºé˜Ÿåˆ—å®ä¾‹
export { redis };
