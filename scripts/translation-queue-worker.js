#!/usr/bin/env node

/**
 * Translation Queue Worker - ç‹¬ç«‹Workerè¿›ç¨‹
 * ç›´æŽ¥åˆ›å»ºQueueå®žä¾‹é¿å…æ¨¡å—åˆå§‹åŒ–é—®é¢˜
 */

import Bull from 'bull';
import { logger } from '../app/utils/logger.server.js';
import { handleTranslateResource, handleBatchTranslate } from '../app/services/queue.server.js';

const SHOP_ID = process.env.SHOP_ID || 'unknown';
const QUEUE_ROLE = process.env.QUEUE_ROLE || 'unknown';
const REDIS_URL = process.env.REDIS_URL;

// âœ… å¯åŠ¨æ—¶éªŒè¯çŽ¯å¢ƒå˜é‡
logger.info('[Worker] Translation queue worker starting', {
  shopId: SHOP_ID,
  queueRole: QUEUE_ROLE,
  nodeEnv: process.env.NODE_ENV,
  hasRedisUrl: !!REDIS_URL,
  redisEnabled: process.env.REDIS_ENABLED
});

if (QUEUE_ROLE !== 'worker') {
  logger.error('[Worker] CRITICAL: QUEUE_ROLE is not "worker"', {
    actual: QUEUE_ROLE,
    expected: 'worker'
  });
}

if (!REDIS_URL) {
  logger.error('[Worker] CRITICAL: Missing REDIS_URL');
  process.exit(1);
}

// ðŸ”¥ ä½¿ç”¨ç»Ÿä¸€çš„DBåˆ†é…é€»è¾‘ï¼ˆä¸Žredis-parser.server.jsä¸€è‡´ï¼‰
function getShopDb(shopId) {
  const normalizedId = (shopId || '').toLowerCase();

  // çŽ¯å¢ƒéš”ç¦»æ˜ å°„
  const dbMap = {
    'lightsler-ai': 10,
    'lightsler': 10,
    'fynony': 11,
    'shop1': 11,
    'onewind': 2,
    'onewindoutdoors': 2,
    'shop2': 2
  };

  // ç²¾ç¡®åŒ¹é…æˆ–åŒ…å«åŒ¹é…
  for (const [key, db] of Object.entries(dbMap)) {
    if (normalizedId === key || normalizedId.includes(key)) {
      logger.info('[Worker] Shop IDæ˜ å°„åˆ°DB', { shopId, db });
      return db;
    }
  }

  logger.warn('[Worker] Shop IDæœªæ˜ å°„ï¼Œä½¿ç”¨é»˜è®¤DB 0', { shopId });
  return 0;
}

// è§£æžRedis URL
const url = new URL(REDIS_URL);
const redisConfig = {
  host: url.hostname,
  port: parseInt(url.port) || 6379,
  password: url.password || undefined,
  db: getShopDb(SHOP_ID),  // ä½¿ç”¨ç»Ÿä¸€çš„DBåˆ†é…å‡½æ•°
  maxRetriesPerRequest: null,  // ç¦ç”¨é™åˆ¶ï¼Œé¿å…BLPOPè¢«ä¸­æ–­
  enableReadyCheck: false,
  connectTimeout: 30000
  // âŒ ä¸è®¾ç½®commandTimeout - BLPOPéœ€è¦é•¿æ—¶é—´ç­‰å¾…
};

logger.info('[Worker] Redis config', {
  host: redisConfig.host,
  port: redisConfig.port,
  db: redisConfig.db,
  hasPassword: !!redisConfig.password
});

// âœ… ç›´æŽ¥åˆ›å»ºQueueå®žä¾‹
const queue = new Bull(`translation_${SHOP_ID}`, {
  redis: redisConfig,
  prefix: `bull:${SHOP_ID}`,
  defaultJobOptions: {
    removeOnComplete: 10,
    removeOnFail: 5,
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000
    }
  },
  settings: {
    stalledInterval: 30000,
    retryProcessDelay: 5000
  }
});

// ðŸ” æ•èŽ·æœªå¤„ç†çš„Promise rejection
process.on('unhandledRejection', (reason, promise) => {
  logger.error('[Worker] Unhandled Promise Rejection', {
    reason: reason,
    reasonType: typeof reason,
    stack: reason?.stack,
    promise: String(promise)
  });
});

// âœ… æ³¨å†Œprocessors
async function start() {
  try {
    logger.info('[Worker] Connecting to Redis queue...');
    await queue.isReady();
    logger.info('[Worker] Queue connection established');

    // æ³¨å†ŒtranslateResource processor
    logger.info('[Worker] Registering translateResource processor');
    queue.process('translateResource', 2, async (job) => {
      logger.info('[Worker] âš¡ Processing translateResource job', { jobId: job.id });
      try {
        const result = await handleTranslateResource(job);
        logger.info('[Worker] âœ… Job completed', { jobId: job.id });
        return result;
      } catch (error) {
        logger.error('[Worker] âŒ Job failed', { jobId: job.id, error: error.message });
        throw error;
      }
    });

    // æ³¨å†ŒbatchTranslate processor
    logger.info('[Worker] Registering batchTranslate processor');
    queue.process('batchTranslate', 1, async (job) => {
      logger.info('[Worker] âš¡ Processing batchTranslate job', { jobId: job.id });
      try {
        const result = await handleBatchTranslate(job);
        logger.info('[Worker] âœ… Batch job completed', { jobId: job.id });
        return result;
      } catch (error) {
        logger.error('[Worker] âŒ Batch job failed', { jobId: job.id, error: error.message });
        throw error;
      }
    });

    logger.info('[Worker] Processors registered successfully');

    // âœ… äº‹ä»¶ç›‘å¬
    queue.on('waiting', (jobId) => {
      logger.info('[Worker Event] Job waiting', { jobId });
    });

    queue.on('active', (job) => {
      logger.info('[Worker Event] Job active', { jobId: job.id, name: job.name });
    });

    queue.on('completed', (job, result) => {
      logger.info('[Worker Event] Job completed', { jobId: job.id });
    });

    queue.on('failed', (job, err) => {
      logger.error('[Worker Event] Job failed', { jobId: job?.id, error: err.message });
    });

    queue.on('error', (error) => {
      logger.error('[Worker] Queue error', { error: error.message });
    });

    logger.info('[Worker] Event listeners attached');

    // âœ… èŽ·å–é˜Ÿåˆ—ç»Ÿè®¡
    const counts = await queue.getJobCounts();

    logger.info('[Worker] Translation queue worker ready âœ…', {
      shopId: SHOP_ID,
      queueRole: QUEUE_ROLE,
      queueName: queue.name,
      counts,
      redisMode: 'redis'
    });

    // å¦‚æžœæœ‰waitingä»»åŠ¡ï¼Œç«‹å³è§¦å‘å¤„ç†
    if (counts.waiting > 0) {
      logger.info('[Worker] Found waiting jobs, worker will start processing', {
        waitingCount: counts.waiting
      });
    }

  } catch (error) {
    logger.error('[Worker] Failed to initialize queue worker âŒ', {
      shopId: SHOP_ID,
      error: error.message,
      stack: error.stack
    });
    process.exit(1);
  }
}

// âœ… ä¼˜é›…å…³é—­
async function gracefulShutdown(signal) {
  logger.info(`[Worker] Received ${signal}, shutting down queue worker`, { shopId: SHOP_ID });
  try {
    await queue.close();
    logger.info('[Worker] Queue closed gracefully');
  } catch (error) {
    logger.warn('[Worker] Failed to close queue gracefully', {
      shopId: SHOP_ID,
      error: error.message
    });
  } finally {
    process.exit(0);
  }
}

process.on('SIGINT', () => gracefulShutdown('SIGINT'));
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));

// âœ… å¯åŠ¨Worker
await start();

// âœ… å¿ƒè·³æ—¥å¿—
setInterval(async () => {
  try {
    const counts = await queue.getJobCounts();
    logger.debug('[Worker] Heartbeat', {
      shopId: SHOP_ID,
      counts
    });
  } catch (error) {
    logger.warn('[Worker] Failed to fetch queue counts', {
      shopId: SHOP_ID,
      error: error.message
    });
  }
}, 60_000);
